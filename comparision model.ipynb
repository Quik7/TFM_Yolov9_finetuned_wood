{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "output_file_path = '/home/llama/Enrique/maderas/output.txt'\n",
        "!python /home/llama/Enrique/maderas/yolov9/segment/predict.py \\\n",
        "--conf 0.2 --device 0 --max-det 1000 \\\n",
        "--weights /home/llama/Enrique/maderas/yolov9/runs/train-seg/gelan-c-seg3/weights/best.pt \\\n",
        "--source /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/ > {output_file_path} 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1msegment/predict: \u001b[0mweights=['/home/llama/Enrique/maderas/yolov9/runs/train-seg/gelan-c-seg3/weights/best.pt'], source=/home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/, data=yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.2, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov9/runs/predict-seg, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1, retina_masks=False\n",
            "YOLO ðŸš€ v0.1-104-g5b1ea9a Python-3.11.9 torch-2.3.0+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24257MiB)\n",
            "\n",
            "Fusing layers... \n",
            "gelan-c-seg summary: 414 layers, 27378319 parameters, 0 gradients, 144.3 GFLOPs\n",
            "image 1/6 /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/0030-1_jpg.rf.9d6568d8c612da31b2472577cea99103.jpg: 640x640 2 Anchura radio celulas 97s, 1 Depositos o gomas 58, 1 Parenquima axial paratraqueal 78, 8 Parenquima axial paratraqueal 80s, 3 Parenquima axial paratraqueal 81s, 6 Parenquima axial paratraqueal 83s, 13 Vaso V2s, 2 Vaso V3s, 12.0ms\n",
            "image 2/6 /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/0030-1_jpg.rf.ec7d31396dbb722c38bcdef111fad582.jpg: 640x640 2 Anchura radio celulas 97s, 1 Depositos o gomas 58, 1 Parenquima axial paratraqueal 78, 8 Parenquima axial paratraqueal 80s, 3 Parenquima axial paratraqueal 81s, 6 Parenquima axial paratraqueal 83s, 13 Vaso V2s, 2 Vaso V3s, 11.9ms\n",
            "image 3/6 /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/0030-6_jpg.rf.728e001481e01825292f263cef614194.jpg: 640x640 6 Anchura radio celulas 97s, 2 Depositos o gomas 58s, 10 Parenquima axial paratraqueal 80s, 5 Parenquima axial paratraqueal 81s, 2 Parenquima axial paratraqueal 82s, 4 Parenquima axial paratraqueal 83s, 17 Vaso V2s, 4 Vaso V3s, 12.1ms\n",
            "image 4/6 /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/0030-8_jpg.rf.327a00164ed7dce2d4998fe7964b6226.jpg: 640x640 5 Anchura radio celulas 97s, 3 Depositos o gomas 58s, 2 Parenquima axial paratraqueal 78s, 5 Parenquima axial paratraqueal 80s, 10 Parenquima axial paratraqueal 81s, 1 Parenquima axial paratraqueal 82, 1 Parenquima axial paratraqueal 83, 1 Thylos 56, 19 Vaso V2s, 5 Vaso V3s, 11.9ms\n",
            "image 5/6 /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/0294-12_jpg.rf.ee4a0d1c3a61b00b3be7dcef7f026a9a.jpg: 640x640 1 Anchura radio celulas 96, 2 Anchura radio celulas 97s, 3 Parenquima en bandas 89s, 1 Porosidad 3, 2 Thylos 56s, 5 Vaso V2s, 12.3ms\n",
            "image 6/6 /home/llama/Enrique/maderas/yolov9/Wood-annotation-9/test/images/0550-4_png.rf.8a2c3c300657bdfe4f3458671f3b521c.jpg: 640x640 5 Anchura radio celulas 99s, 2 Disposicion vasos 6s, 15 Disposicion vasos 8s, 1 Porosidad 3, 5 Thylos 56s, 1 Vaso V2, 12.0ms\n",
            "Speed: 0.4ms pre-process, 12.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov9/runs/predict-seg/exp17\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read the output file\n",
        "with open('output.txt', 'r') as file:\n",
        "    output_text = file.read()\n",
        "\n",
        "print(output_text) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Read the output file and filter lines starting with \"image\"\n",
        "with open(output_file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "image_lines = [line for line in lines if line.startswith(\"image\")]\n",
        "\n",
        "# Transform each line to keep only the image name and everything after \"640x640\"\n",
        "transformed_lines = []\n",
        "for line in image_lines:\n",
        "    parts = line.split(\"640x640\")\n",
        "    if len(parts) > 1:\n",
        "        image_name = parts[0].split('/')[-1].split(':')[0].strip()\n",
        "        rest_of_line = parts[1].strip()\n",
        "        transformed_line = f\"{image_name}: {rest_of_line}\"\n",
        "        transformed_lines.append(transformed_line)\n",
        "\n",
        "# Join the transformed lines back into a single string if needed for further processing\n",
        "filtered_output_text = '\\n'.join(transformed_lines)\n",
        "\n",
        "filtered_output_path = '/home/llama/Enrique/maderas/filtered_output.txt'\n",
        "with open(filtered_output_path, 'w') as file:\n",
        "    file.write(filtered_output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([{'name': '0030-1_jpg.rf.9d6568d8c612da31b2472577cea99103.jpg',\n",
              "   'code': '97,58,78,80,81,83,V2,V3'},\n",
              "  {'name': '0030-1_jpg.rf.ec7d31396dbb722c38bcdef111fad582.jpg',\n",
              "   'code': '97,58,78,80,81,83,V2,V3'},\n",
              "  {'name': '0030-6_jpg.rf.728e001481e01825292f263cef614194.jpg',\n",
              "   'code': '97,58,80,81,82,83,V2,V3'},\n",
              "  {'name': '0030-8_jpg.rf.327a00164ed7dce2d4998fe7964b6226.jpg',\n",
              "   'code': '97,58,78,80,81,82,83,56,V2,V3'},\n",
              "  {'name': '0294-12_jpg.rf.ee4a0d1c3a61b00b3be7dcef7f026a9a.jpg',\n",
              "   'code': '96,97,89,3,56,V2'},\n",
              "  {'name': '0550-4_png.rf.8a2c3c300657bdfe4f3458671f3b521c.jpg',\n",
              "   'code': '99,6,8,3,56,V2'}],\n",
              " 'output_processed.json')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "# Read the input file\n",
        "file_path = 'filtered_output.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    input_data = file.readlines()\n",
        "\n",
        "output = []\n",
        "\n",
        "for line in input_data:\n",
        "    # Step 1: Remove the Xms patterns (where X can be any number or a decimal number)\n",
        "    cleaned_data = re.sub(r'\\d+\\.\\d+ms', '', line)\n",
        "\n",
        "    # Step 2: Split based on the rules provided\n",
        "    file_name, attributes = cleaned_data.split(':')\n",
        "    attributes_list = attributes.split(',')\n",
        "\n",
        "    # Step 3: Process each attribute\n",
        "    processed_attributes = []\n",
        "    for attribute in attributes_list:\n",
        "        attribute = attribute.strip()\n",
        "        if attribute:\n",
        "            if attribute.endswith('s'):\n",
        "                processed_attributes.append(attribute[:-1])\n",
        "            else:\n",
        "                processed_attributes.append(attribute)\n",
        "\n",
        "    # Create the final dictionary\n",
        "    final_numbers = [attr.split()[-1] for attr in processed_attributes]\n",
        "    final_numbers = [num if not num.isdigit() else str(int(num)) for num in final_numbers]\n",
        "    final_numbers = \",\".join(final_numbers)\n",
        "\n",
        "    # Append to output list\n",
        "    output.append({\n",
        "        \"name\": file_name.strip(),\n",
        "        \"code\": final_numbers\n",
        "    })\n",
        "\n",
        "# Save the result to a JSON file\n",
        "output_file_path = 'output_processed.json'\n",
        "with open(output_file_path, 'w') as f:\n",
        "    json.dump(output, f, indent=4)\n",
        "\n",
        "output, output_file_path\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'predictions.csv'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load JSON data\n",
        "with open('output_processed.json', 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "# Load Excel data\n",
        "excel_file_path = '2024_05_13 Listado EUTR_codigos.xlsx'\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Prepare the data for comparison\n",
        "codigos = df['Codigos '].astype(str).tolist()  # Note the space at the end of 'Codigos '\n",
        "scientific_names = df['NOMBRE CIENTIFICO'].tolist()\n",
        "\n",
        "# Function to get top 5 matches by number of matching elements\n",
        "def get_top_matches_by_coincidence(input_code, codigos, scientific_names):\n",
        "    input_set = set(input_code.split(','))\n",
        "    match_counts = []\n",
        "    \n",
        "    for idx, code in enumerate(codigos):\n",
        "        code_set = set(code.split(','))\n",
        "        common_elements = input_set.intersection(code_set)\n",
        "        match_counts.append((len(common_elements), scientific_names[idx], code))\n",
        "    \n",
        "    # Sort by number of matches in descending order and get top 5\n",
        "    top_matches = sorted(match_counts, key=lambda x: x[0], reverse=True)[:5]\n",
        "    return [(match[1], match[2], match[0]) for match in top_matches]\n",
        "\n",
        "# Compare and predict top 5 candidates for each name in JSON\n",
        "predictions = []\n",
        "for item in json_data:\n",
        "    name = item['name']\n",
        "    code = item['code']\n",
        "    top_matches = get_top_matches_by_coincidence(code, codigos, scientific_names)\n",
        "    predictions.append({\n",
        "        \"name\": name,\n",
        "        \"predictions\": top_matches\n",
        "    })\n",
        "\n",
        "# Save the predictions to a new JSON file\n",
        "output_predictions_path = 'coincidence_predictions.json'\n",
        "with open(output_predictions_path, 'w') as f:\n",
        "    json.dump(predictions, f, indent=4)\n",
        "\n",
        "output_predictions_path\n",
        "\n",
        "# Convert predictions to CSV format\n",
        "csv_data = []\n",
        "for pred in predictions:\n",
        "    for match in pred['predictions']:\n",
        "        csv_data.append([pred['name'], match[0], match[1], match[2]])\n",
        "\n",
        "# Create a DataFrame and save to CSV\n",
        "csv_df = pd.DataFrame(csv_data, columns=['Name', 'Predicted Scientific Name', 'Codigo', 'Match Count'])\n",
        "csv_output_path = 'predictions.csv'\n",
        "csv_df.to_csv(csv_output_path, index=False)\n",
        "\n",
        "csv_output_path"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
